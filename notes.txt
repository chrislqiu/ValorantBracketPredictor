 venv\Scripts\Activate.ps1  <-- to activate venv to isolate packages
 pip freeze > requirements.txt <-- updates environment for venv

 Mistakes:
 - tried to push venv (LOL), put it in gitignore

What I did after:

pip install requests pandas numpy scikit-learn xgboost <-- installing all the imports I need
    - requests for API
    - numpy to work with the data
    - scikit-learn lib for ML tools
- xgboost notes cause I've never used it before:
    * extreme gradient  boosting
    * combines multiple weak models to create stronger models
    * use errors on prev test to train next tree using regularization to prevent overfitting
    * repeat the process
    * sequential

Need Scraper to pull info from VLR.gg/matches/results
    - need team name and score (for now)
    - include other data like player composition (later)

Beautiful Soup Notes:
- soup = BeautifulSoup(res.text, "html.parser) <-- to use soup.find_all etc
- .text after a .find() to obtain the text (need this to extract team name and score)
- be wary of errors/inconsistencies in html
- need to access each nested div, span, a, etc
- soup.select() <-- allows multiple selection of class name separated by .

docs here: https://beautiful-soup-4.readthedocs.io/en/latest/#

pip install beautifulsoup4

ACTUAL SCRAPING STUFF:
- need to take into account BO1 --> done, check by summing the scores to see if they exceed 5 (BO5 and BO3 max is 5 and 3 respectively)
- only take into teams that actually show up on brackets (tier 1 teams)

MODEL NOTES:

- Using binary to signify who won. 1 means team 1 won, 0 means team 1 loss (team 2 won)
- xgboost uses decision trees. the threshold is learned through internal gain calculations

json -> csv: ML cannot read nested data, so we convert json to csv to flatten it. Basically spreadsheet format

use csv to train data, and utilize historical team data to strengthen model

match_dataset.csv rows

match_id
team1
team2
winner -> 0/1
t1_winrate -> winrate of matches before current
t1_winrate
winrate_diff
t1_recent_form -> win rate in the last 10 matches
t2_recent_form
form_diff
t1_avg_rnd_diff -> avg rnd diff in last 5 matches (winning/losing by x rnds)
t1_avg_rnd_diff
rnd_diff_diff -> difference between avg rnd diff
#current map data
avg_map_rnd_diff -> avg rnd diff across the maps in this match_dataset
maps_won_t1
maps_won_t2
total_rnd_diff
total_score

joblib import -> good for lightweight pipeline for large data

Under the hood:

Tree 0:
[winrate_diff < 0.052]  # Level 1 split
├── Yes: [form_diff < -0.123]  # Level 2 split
│   ├── Yes: leaf = 0.34  # Terminal node
│   └── No: leaf = 0.67   # Terminal node
└── No: [rnd_diff_diff < -1.5]  # Level 2 split
    ├── Yes: leaf = 0.82  # Terminal node  
    └── No: leaf = 0.45   # Terminal node

- For each leaf, there is a value, positive means T1 favored and negative means T2 favored

It takes the decision leaf of 100 trees to make its prediciton:

Tree 0: 0.67  (Team1 favored)
Tree 1: -0.42 (Team2 favored)
Tree 2: 0.18  (Slight Team1 edge)
Tree 3: -0.89 (Strong Team2 advantage)
Tree 4: 0.31  (Team1 favored)
...
Tree 499: -0.05 (Slight Team2 edge)

Sums it to decide on final decision, and uses sigmoid function to convert to probability (0 to 1)

What each XGBoost stores:

node = {
    "feature": "winrate_diff",    # Which feature to check
    "threshold": 0.052,           # What value to compare against
    "left_child": node_id_2,      # Go here if condition TRUE
    "right_child": node_id_3,     # Go here if condition FALSE
    "gain": 0.45,                 # How useful this split is
    "cover": 125                  # How many samples pass through
}

# Each leaf node contains:
leaf = {
    "leaf_value": 0.67,           # Raw prediction score
    "cover": 42                   # How many samples end up here
}

- At the leaf level, it uses log loss initially, then calculates gradient (how wrong it is),
  then hessian (how confident in gradient)


V2:

- Want to include players statistics since team changes roster
    - what statistics determine performance?
    - stats that everyone has: ACS, KD, KPR, ADR
- Need to first find the players on all the teams OR add team abbreviations and save stats with team abbreviation in the list
    - then get stats for all the players

PLAN:
- build another scraper for https://www.vlr.gg/stats/?event_group_id=all&region=all&min_rounds=200&min_rating=1550&agent=all&map_id=all&timespan=90d
- use hash to find abbreviated name and use full name as val {SEN: Sentinels}
- the output will be a new json with the format:

	{"FULL TEAM NAME" : {
			"stat1" : [x, y, z],
			"stat2" : [x, y, z],
			...
			},
	 "FULL TEAM NAME 2" : {},
		...
	}

- using this new json, import it in vlr_scraper to get player data and save feature
- ISSUE: Not always up to date with players and team and coaches can be in the data
    - scrape through each team page to get the players individually and store them
    - using name along with vlr to get stats
    - if player is Sub or inactive, exclude them from stats
    - check if name and team name in in the list
        - theres multiple people with same names, create a special key name_team to differentiate and prevent overwriting

Stats I want:
-rating
-ACS
-KD
-KAST
-ADR
-KPR
-APR
-FKPR