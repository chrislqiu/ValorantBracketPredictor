 venv\Scripts\Activate.ps1  <-- to activate venv to isolate packages
 pip freeze > requirements.txt <-- updates environment for venv

 Mistakes:
 - tried to push venv (LOL), put it in gitignore

What I did after:

pip install requests pandas numpy scikit-learn xgboost <-- installing all the imports I need
    - requests for API
    - numpy to work with the data
    - scikit-learn lib for ML tools
- xgboost notes cause I've never used it before:
    * extreme gradient  boosting
    * combines multiple weak models to create stronger models
    * use errors on prev test to train next tree using regularization to prevent overfitting
    * repeat the process
    * sequential

Need Scraper to pull info from VLR.gg/matches/results
    - need team name and score (for now)
    - include other data like player composition (later)

Beautiful Soup Notes:
- soup = BeautifulSoup(res.text, "html.parser) <-- to use soup.find_all etc
- .text after a .find() to obtain the text (need this to extract team name and score)
- be wary of errors/inconsistencies in html
- need to access each nested div, span, a, etc
- soup.select() <-- allows multiple selection of class name separated by .

docs here: https://beautiful-soup-4.readthedocs.io/en/latest/#

pip install beautifulsoup4

ACTUAL SCRAPING STUFF:
- need to take into account BO1 --> done, check by summing the scores to see if they exceed 5 (BO5 and BO3 max is 5 and 3 respectively)
- only take into teams that actually show up on brackets (tier 1 teams)

MODEL NOTES:

- Using binary to signify who won. 1 means team 1 won, 0 means team 1 loss (team 2 won)

json -> csv: ML cannot read nested data, so we convert json to csv to flatten it. Basically spreadsheet format

use csv to train data, and utilize historical team data to strengthen model